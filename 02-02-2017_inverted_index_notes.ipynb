{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chapter 2 regex text normalization edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "web or frame url here"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('image url here')\n",
    "HTML('web or frame url here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "lemmatization: determining if words have the same root, ex, sung, sang, sings - all root is sing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# regex module\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.match(r'\\\\ko*', r'\\ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = re.compile('[a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.match('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = p.match('tempo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. group() \tReturn the string matched by the RE\n",
    "2. start() \tReturn the starting position of the match\n",
    "3. end() \tReturn the ending position of the match\n",
    "4. span() \tReturn a tuple containing the (start, end) positions of the match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. match() \tDetermine if the RE matches at the beginning of the string.\n",
    "2. search() \tScan through a string, looking for any location where this RE matches.\n",
    "3. findall() \tFind all substrings where the RE matches, and returns them as a list.\n",
    "4. finditer() \tFind all substrings where the RE matches, and returns them as an iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ex\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(p.match(':::message'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(p.search('::::message')); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = p.search('::::message'); m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('koo', 'kootkikkoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('[Kk1]', 'kooty')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [^A-z] - not an upper case letter\n",
    "2. [^\\.] - not a period ^ - means not now, but only at the beginnning\n",
    "3. [a^] - string a^\n",
    "3. ? - optional element\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('cats?', 'cat') # zero or none previous char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('cats?', 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. *(Kleeny star) - zero or more of previous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('ba*', 'baa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.match('ba*', 'cb')# not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# . any single char\n",
    "re.match('a.d', 'aad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.match('a.d', 'ad') # not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  $ - matches the end of line _$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('sd$', 'sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(' $', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('s\\\\\\\\', r's\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \\b word boundary\n",
    "re.search(r'\\b99\\b', r's 99 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(r'\\b99\\b', r's $99 ') # match because $ is not digot underscore, digits or letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# | disjunction matches left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(r'cat|dog', r' is enemy of  cat ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(4, 6), match='pb'>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'[\\w](b)', r' guppb') # round brackets (,) takes precedence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also used to:\n",
    "re.search('( Column [0-9]+ *)*', ' Column 9    and')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Precedence:\n",
    "1. ()\n",
    "2. * + ? {}\n",
    "3. Seuences and anchors : the ^my end$\n",
    "4. Disjunction |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-940263ba5fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# simple match word the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(^|[^a-zA-Z])[tT]he([^a-zA-Z]|$)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' the rock'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# matches the at he beginning or end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                                              \u001b[0;31m# or not surrounded by letters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "# simple match word the\n",
    "\n",
    "p = re.search('(^|[^a-zA-Z])[tT]he([^a-zA-Z]|$)', ' the rock')# matches the at he beginning or end\n",
    "                                                             # or not surrounded by letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p;p is None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('\\\\b[0-9]+(\\.[0-9]+)? *(GB|[Gg]igabytes?)\\\\b', '$345.00 GB 300') # matches price in dol and hd spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# {<number>} -  exactly number occurences of prievous expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('(kocham koty){2}', 'kocham kotykocham koty') # mtch kocham kot exactly twice"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "special shortcuts:\n",
    "1. \\d - [0-9]\n",
    "2. \\D - [^0-9] \n",
    "3. \\w - [a-zA-Z_] - any allphanumeric/underscore\n",
    "4. \\W - non alphanumeric\n",
    "5. \\s - [_\\r\\t\\n\\f] - any whitespace\n",
    "6. \\S - non whitespace\n",
    "7. {n, m} - from n to m occurences prievous expr\n",
    "8. {n, } - at least n occurences prievous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-94bfc9d8b2a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the (.*)er they were, the \\1er they will be'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the bigger they were, the bigger they will be'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "re.match('the (.*)er they were, the \\1er they will be', 'the bigger they were, the bigger they will be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-682f9410c6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'....'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'dranie'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'supa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "re.sub(r'....', r'dranie', r'supa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! sed -e 's/a/b/g' text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! cat text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lemma is set of lexical forms which have the same steam and the same word sense cat, cats\n",
    "# types: number of differentt words\n",
    "# tokens: number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! tr -sc 'a-zA-Z' '\\n' < text.txt | head # split using new line as a separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! tr -sc 'a-zA-Z' '\\n' < text.txt | tr A-Z a-z | sort | uniq -c | head #  collapse all to lower case, sort and collapse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! tr -sc 'a-zA-Z' '\\n' < text.txt | tr A-Z a-z | sort | uniq -c | sort -n -r # and finally sort numerically to get freq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization - separating text into tokens /words - problems with prices, shortcuts, dates, numbers, mail addresses, html addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max match algorithm\n",
    "D = ['danny', 'kondory', 'a', 'the','to','has', 'been', 'unable', 'go' ]\n",
    "#D = ['d', 'a', 'n' ]\n",
    "def max_match(sentence, dictionary):\n",
    "    if not sentence:\n",
    "        return \"\"\n",
    "    for i in range(len(sentence), -1, -1):\n",
    "        first_word = sentence[:i]\n",
    "        remainder = sentence[i:]\n",
    "        if first_word in dictionary:\n",
    "            return first_word + \" \" +  max_match(remainder, dictionary)\n",
    "    first_word = sentence[0]\n",
    "    remainder = sentence[1:]\n",
    "    return first_word + max_match(remainder, dictionary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the been kondory go unable \n"
     ]
    }
   ],
   "source": [
    "sent = \"the\" # len = 3\n",
    "\n",
    "sentence = sent.split()\n",
    "print(max_match(\"thebeenkondorygounable\", D))\n",
    "#sent[3:]\n",
    "#type(sent[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st1 = [1, 3 ,4 ,5 ]\n",
    "st1[1:].append(st1[0])\n",
    "print(st1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Lemmatization - process to determine if words have the same root depite surface differences: am, are, is ia all\n",
    "to be.\n",
    "This can be done by morfological parsing (morfology - science which search jow words was created, and how are built from smaller parts called morphemes) - find class of morphemes: stems - centarl part of the word; affixes- additional changes to word; ex. cats - cat = stem, s = affix. Morfological parser can do this split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit distance algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# edit distance in both recursive (not to be used to slow) and dynamic programming version\n",
    "# recursive:\n",
    "def d(s1, s2):\n",
    "    if len(s1) == 0 and len(s2) == 0:\n",
    "        return 0\n",
    "    elif len(s1) == 0 and len(s2) != 0:\n",
    "        return len(s2)\n",
    "    elif len(s2) == 0 and len(s1) != 0:\n",
    "        return len(s1)\n",
    "    else:\n",
    "        return min(d(s1[:-1], s2[:-1]) + comp_lasts(s1[-1], s2[-1]),\n",
    "                   d(s1, s2[:-1]) + 1,\n",
    "                   d(s1[:-1], s2) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dynaic programming:\n",
    "def editDistDP(str1, str2, m, n):\n",
    "    # Create a table to store results of subproblems\n",
    "    dp = [[0 for x in range(n + 1)] for x in range(m + 1)]\n",
    "\n",
    "    # Fill d[][] in bottom up manner\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "\n",
    "            # If first string is empty, only option is to\n",
    "            # isnert all characters of second string\n",
    "            if i == 0:\n",
    "                dp[i][j] = j  # Min. operations = j\n",
    "\n",
    "            # If second string is empty, only option is to\n",
    "            # remove all characters of second string\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i  # Min. operations = i\n",
    "\n",
    "            # If last characters are same, ignore last char\n",
    "            # and recur for remaining string\n",
    "            elif str1[i - 1] == str2[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "\n",
    "            # If last character are different, consider all\n",
    "            # possibilities and find minimum\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i][j - 1],  # Insert\n",
    "                                   dp[i - 1][j],  # Remove\n",
    "                                   dp[i - 1][j - 1])  # Replace\n",
    "\n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st1 = \"sunday euheu jodjod\"\n",
    "st2 = \"saturdaydkwdwmmdwod\"\n",
    "print(editDistDP(st1, st2, len(st1), len(st2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find set of all alphabetic strings\n",
    "re.search(r'(^|[ ])(a-z(b))+([ ]|$)', r'werb')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(r\"^[-+]?[0-9]+\\.[0-9]+$\", r\"-22.9\") # matches float poiunt numbers only in form +-2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 5), match='zosia'>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r'\\b[Zz]osia\\b', r'zosf ia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 45), match='www.hdomain.rozrywka.onet.pl/xyx/abc/uff.html'>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"^(https?:\\/\\/|www\\.)?([a-z]+\\.)+[a-z]+((\\/[a-z]+)*[a-z]+\\.[a-z]+)*$\", r\"www.hdomain.rozrywka.onet.pl/xyx/abc/uff.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uns_num(x):\n",
    "    if x < 0:\n",
    "        return (x + 2**32)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def bound(a, x, b):\n",
    "    \n",
    "    return uns_num(x - a) <= b - a\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(bound(1, -10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.search(r\"(?<=title=\\\").*?(?=\\\")\", r\"title=\\\"Image\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#re.search(r\"^dim( \\. )?(\\\\)?t[0-9]+$\", r\"dim\\t65\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time.struct_time(tm_year=2009, tm_mon=3, tm_mday=27, tm_hour=22, tm_min=20, tm_sec=42, tm_wday=4, tm_yday=86, tm_isdst=-1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shell = 1\n",
    "entry = {}                                                                                         \n",
    "entry['title'] = 'Dive into history, 2009 edition'\n",
    "entry['article_link'] = 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition'\n",
    "entry['comments_link'] = None\n",
    "entry['internal_id'] = b'\\xDE\\xD5\\xB4\\xF8'\n",
    "entry['tags'] = ('diveintopython', 'docbook', 'html')\n",
    "entry['published'] = True\n",
    "import time\n",
    "entry['published_date'] = time.strptime('Fri Mar 27 22:20:42 2009')                                \n",
    "entry['published_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = [1,entry]\n",
    "import pickle\n",
    "with open('entry.pickle', 'wb') as f:\n",
    "    pickle.dump(l[1], f)\n",
    "#del(entry)\n",
    "\n",
    "#del(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_link': 'http://diveintomark.org/archives/2009/03/27/dive-into-history-2009-edition',\n",
       " 'comments_link': None,\n",
       " 'internal_id': b'\\xde\\xd5\\xb4\\xf8',\n",
       " 'published': True,\n",
       " 'published_date': time.struct_time(tm_year=2009, tm_mon=3, tm_mday=27, tm_hour=22, tm_min=20, tm_sec=42, tm_wday=4, tm_yday=86, tm_isdst=-1),\n",
       " 'tags': ('diveintopython', 'docbook', 'html'),\n",
       " 'title': 'Dive into history, 2009 edition'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('entry.pickle', 'rb') as f:\n",
    "    l[1] = pickle.load(f)\n",
    "l[1]\n",
    "#entry['00added4'] = 'test4 data'\n",
    "#del(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prices = [5, 12, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, len(prices)):\n",
    "    exec(\"price%d = %s\" % (i + 1, repr(prices[i])));\n",
    "type(price1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while i < cnt_docs:\\n    s = \"doc%s.pickle\" % i\\n    with open(s, \\'wb\\') as f:\\n         pickle.dump(s, f)\\n         print(s, type(s))\\n       \\n    i += 1\\n## we have d0.pickle and d1.pickle on disk   \\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "doc1 = \"\"\"I did enact Julius Caesar  I was killed\n",
    "i the Capitol , Brutus killed me\"\"\"\n",
    "doc2 = \"\"\"So let it be with Caesar. The noble Brutus\n",
    "hath told you Caesar was ambitious:\"\"\"\n",
    "cnt_docs = 2\n",
    "i = 0\n",
    "'''while i < cnt_docs:\n",
    "    s = \"doc%s.pickle\" % i\n",
    "    with open(s, 'wb') as f:\n",
    "         pickle.dump(s, f)\n",
    "         print(s, type(s))\n",
    "       \n",
    "    i += 1\n",
    "## we have d0.pickle and d1.pickle on disk   \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b''\n",
      "b''\n",
      "[b'\\x80\\x03X\\x0b\\x00\\x00\\x00doc0.pickleq\\x00.']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < cnt_docs:\n",
    "    s = \"doc%s.pickle\" % i\n",
    "    with open(s, 'rb') as f:\n",
    "        #print(s)\n",
    "        pickle.load(f)\n",
    "        print(f.readline())\n",
    "    i += 1\n",
    "f1 = open('doc0.pickle', 'rb')\n",
    "print(f1.readlines())\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¿½\u0003X\u000b",
      "\u0000\u0000\u0000doc0.pickleq\u0000."
     ]
    }
   ],
   "source": [
    "! cat doc0.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find(elem, d_list):\n",
    "    l_return = []\n",
    "    i = 0\n",
    "    for x in d_list:\n",
    "        if elem in x:\n",
    "            l_return.append(i)\n",
    "        i += 1\n",
    "    return (l_return, len(l_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',',\n",
       " 'brutus',\n",
       " 'caesar',\n",
       " 'capitol',\n",
       " 'did',\n",
       " 'enact',\n",
       " 'i',\n",
       " 'julius',\n",
       " 'killed',\n",
       " 'me',\n",
       " 'the',\n",
       " 'was'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(doc1.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doc1'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works assuming, that a two single documents will fit into memory...\n",
    "from collections import deque\n",
    "\n",
    "d1 = ['i', 'did', 'enact', 'julius', 'caesar', 'i', 'was', 'kill' , 'i', 'the', 'capitol',  'brutus','me']\n",
    "d1 = set(d1)\n",
    "d2 = ['i', 'so', 'let', 'it', 'be', 'with' , 'caesar', 'the', 'noble', 'brutus', 'hath', 'told', 'you', \n",
    "      'caesar', 'was', 'ambitious']\n",
    "d2 = set(d2)\n",
    "files = {'1': d1, '2': d2}\n",
    "# d1, d2 lists with serialized, tokenized documents need to be procesed one by one in a loop,\n",
    "# counted and dumped to disk, we already have a dict with files and pointers to them \n",
    "doc_list = deque()\n",
    "doc_list.append(d1)\n",
    "doc_list.append(d2)\n",
    "##print(doc_list)\n",
    "\n",
    "tokens = d1.union(d2)\n",
    "## print(\"tokens\", tokens)\n",
    "inv_index = {}\n",
    "for x in tokens:\n",
    "    tmp, tmp1 = find(x, doc_list)\n",
    "    inv_index[(x, tmp1)] = tmp \n",
    "\n",
    "def AND(w1, w2):\n",
    "    tmp0 =  set(inv_index[find_key(w1, inv_index)])\n",
    "    tmp1 =  set(inv_index[find_key(w2, inv_index)])\n",
    "    indexes = tmp0.intersection(tmp1)\n",
    "    ret_list = []\n",
    "    for x in indexes:\n",
    "        ret_list.append(x)\n",
    "    return ret_list\n",
    "\n",
    "def OR(w1, w2):\n",
    "    tmp0 =  set(inv_index[find_key(w1, inv_index)])\n",
    "    tmp1 =  set(inv_index[find_key(w2, inv_index)])\n",
    "    indexes = tmp0.union(tmp1)\n",
    "    ret_list = []\n",
    "    for x in indexes:\n",
    "        ret_list.append(x)\n",
    "    return ret_list\n",
    "    \n",
    "def NOT(w1):\n",
    "    tmp0 =  set(inv_index[find_key(w1, inv_index)])\n",
    "    indexes = list(tmp0)\n",
    "    ret_list = []\n",
    "    for x in range(len(doc_list)):\n",
    "        if x not in indexes:\n",
    "            ret_list.append(x)\n",
    "    return ret_list\n",
    "\n",
    "def NOT1(l1):\n",
    "    #tmp0 =  set(inv_index[find_key(w1, inv_index)])\n",
    "    indexes = l1\n",
    "    ret_list = []\n",
    "    for x in range(len(doc_list)):\n",
    "        if x not in indexes:\n",
    "            ret_list.append(x)\n",
    "    return ret_list\n",
    "        \n",
    "    \n",
    "    \n",
    "AND('the', 'i')\n",
    "OR('let', 'you')\n",
    "\n",
    "\n",
    "\n",
    "s = set()\n",
    "s.add(\"A\")\n",
    "s.add(\"B\")\n",
    "s.add(\"C\")\n",
    "not \"C\" in s\n",
    "inv_index[find_key('the', inv_index)]\n",
    "\n",
    "(inv_index[find_key('it', inv_index)] or inv_index[find_key('let', inv_index)]) and( not inv_index[find_key('capitol', inv_index)])\n",
    "\n",
    "list(inv_index.values())\n",
    "list(set(inv_index[find_key('i', inv_index)]))\n",
    "#OR('let', 'you')\n",
    "OR('so', 'i')\n",
    "#NOT('did')\n",
    "#AND('did', 'it')\n",
    "#NOT1([0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find(elem, d_list):\n",
    "    l_return = []\n",
    "    i = 0\n",
    "    for x in d_list:\n",
    "        if elem in x:\n",
    "            l_return.append(i)\n",
    "        i += 1\n",
    "    return (l_return, len(l_return))\n",
    "\n",
    "def find_key(x, d):\n",
    "    for y in d.keys():\n",
    "        if x in y:\n",
    "            return y\n",
    "    return \"word not in a texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! mv daily/language_processing.ipynb daily/26-01-2017_language_processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = [0, 1, 2]\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = deque()\n",
    "d.appendleft(1)\n",
    "d\n",
    "d.appendleft(2)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('l[2].pickle', 'wb') as f:\n",
    "    pickle.dump(l[2], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('l[2].pickle', 'rb') as f:\n",
    "    l.append(pickle.load(f))\n",
    "l[2]\n",
    "\n",
    "#entry['00added4'] = 'test4 data'\n",
    "#del(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdiwhd\\n', 'dwihdw\\n', 'niwd']\n"
     ]
    }
   ],
   "source": [
    "f = open('text.txt', 'r')\n",
    "print(f.readlines())\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing text.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile text.txt\n",
    "hdiwhd\n",
    "dwihdw\n",
    "niwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mv /home/lion/projects/daily_uploads/language_processing.ipynb /home/lion/projects/daily_uploads/26-01-2017_inverted_index_notes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american_fkah.ipynb  functions_and_tree_class.py  regexp.py\r\n",
      "Awk\t\t     main_function.py\t\t  tests\r\n",
      "chap1\t\t     parse_tree.py\t\t  texts\r\n",
      "Crawler.ipynb\t     porpositional_logic_eval.py\r\n",
      "daily_uploads\t     __pycache__\r\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "! ls /home/lion/projects/python/nlp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cp /home/lion/projects/python/nlp/porpositional_logic_eval.py /home/lion/projects/daily_uploads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from porpositional_logic_eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import string\r\n",
      "import re\r\n",
      "import operator as op\r\n",
      "import functools\r\n",
      "from itertools import product\r\n",
      "\r\n",
      "\r\n",
      "class BinaryTree: \r\n",
      "    def __init__(self, rootObj):\r\n",
      "        self.key = rootObj\r\n",
      "        self.parent = None\r\n",
      "        self.leftChild = None\r\n",
      "        self.rightChild = None\r\n",
      "\r\n",
      "    def insertLeft(self, newNode):\r\n",
      "        if self.leftChild == None:\r\n",
      "            t = BinaryTree(newNode)\r\n",
      "            self.leftChild = t\r\n",
      "            t.parent = self\r\n",
      "        else:\r\n",
      "            t = BinaryTree(newNode)\r\n",
      "            t.parent = self\r\n",
      "            t.leftChild = self.leftChild\r\n",
      "            self.leftChild.parent = t\r\n",
      "            self.leftChild = t\r\n",
      "\r\n",
      "    def insertRight(self, newNode):\r\n",
      "        if self.rightChild == None:\r\n",
      "            t = BinaryTree(newNode)\r\n",
      "            self.rightChild = t\r\n",
      "            t.parent = self\r\n",
      "        else:\r\n",
      "            t = BinaryTree(newNode)\r\n",
      "            t.parent = self\r\n",
      "            t.rightChild = self.rightChild\r\n",
      "            self.rightChild.parent = t\r\n",
      "            self.rightChild = t\r\n",
      "\r\n",
      "    def getRightChild(self):\r\n",
      "        return self.rightChild\r\n",
      "\r\n",
      "    def getLeftChild(self):\r\n",
      "        return self.leftChild\r\n",
      "\r\n",
      "    def getParent(self):\r\n",
      "        return self.parent\r\n",
      "\r\n",
      "    def getRootVal(self):\r\n",
      "        return self.key\r\n",
      "\r\n",
      "    def setRootVal(self, obj):\r\n",
      "        self.key = obj\r\n",
      "\r\n",
      "    def setLeftChild(self, nodeObj):\r\n",
      "        self.leftChild = nodeObj\r\n",
      "\r\n",
      "    def setRightChild(self, nodeObj):\r\n",
      "        self.rightChild = nodeObj\r\n",
      "\r\n",
      "    def setParent(self, nodeObj):\r\n",
      "        self.parent = nodeObj\r\n",
      "\r\n",
      "    def isRightChild(self):\r\n",
      "        return self.parent and self.parent.rightChild == self\r\n",
      "\r\n",
      "    def isLeftChild(self):\r\n",
      "        return self.parent and self.parent.leftChild == self\r\n",
      "\r\n",
      "    def isRoot(self):\r\n",
      "        return\r\n",
      "\r\n",
      "\r\n",
      "def inorder_traversal(tree):\r\n",
      "    if tree:\r\n",
      "        inorder_traversal(tree.getLeftChild())\r\n",
      "        print(tree.getRootVal())\r\n",
      "        inorder_traversal(tree.getRightChild())\r\n",
      "        \r\n",
      "implication = lambda x, y: op.or_(op.not_(x), y)\r\n",
      "equality = lambda x ,y: op.and_(implication(x, y), implication(y, x))\r\n",
      "xor = lambda x, y: op.and_(op.or_(x, y), op.not_(op.and_(x, y)))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def build_parse_tree(exp):\r\n",
      "    exp_list = exp.replace('(', ' ( ').replace(')', ' ) ').replace('~', ' ~ ').split()\r\n",
      "    e_tree = BinaryTree('')\r\n",
      "    current_tree = e_tree\r\n",
      "    for token in exp_list:\r\n",
      "        if token == '(':\r\n",
      "                current_tree.insertLeft('')\r\n",
      "                current_tree = current_tree.getLeftChild()\r\n",
      "        elif token in ['||','&&', '->', '==', 'XR']:\r\n",
      "            if current_tree.getRootVal() == '~':\r\n",
      "                current_tree.getParent().setRootVal(token)\r\n",
      "                current_tree.insertRight('')\r\n",
      "                current_tree = current_tree.getRightChild()\r\n",
      "            else:\r\n",
      "                current_tree.setRootVal(token)\r\n",
      "                current_tree.insertRight('')\r\n",
      "                current_tree = current_tree.getRightChild()\r\n",
      "        elif token in ['1', '0']:\r\n",
      "            current_tree.setRootVal(bool(int(token)))\r\n",
      "            current_tree = current_tree.getParent()\r\n",
      "            if current_tree.getRootVal() == '~':\r\n",
      "                current_tree = current_tree.getParent()\r\n",
      "        elif token == '~':\r\n",
      "            current_tree.setRootVal('~')\r\n",
      "            current_tree.insertLeft('')\r\n",
      "            current_tree = current_tree.getLeftChild()\r\n",
      "        elif token == ')':\r\n",
      "            current_tree = current_tree.getParent()\r\n",
      "        else:\r\n",
      "            raise ValueError\r\n",
      "    return e_tree\r\n",
      "\r\n",
      "def evaluate_parse_tree(tree):\r\n",
      "    opers = {'||': op.or_, '&&': op.and_, '~': op.not_, '->': implication, '==': equality, 'XR': xor} \r\n",
      "    leftT = tree.getLeftChild()\r\n",
      "    rightT = tree.getRightChild()\r\n",
      "    if leftT and not rightT:\r\n",
      "        fn = opers[tree.getRootVal()]\r\n",
      "        return fn(evaluate_parse_tree(leftT))\r\n",
      "    elif leftT and rightT:\r\n",
      "        fn = opers[tree.getRootVal()]\r\n",
      "        return fn(evaluate_parse_tree(leftT), evaluate_parse_tree(rightT))\r\n",
      "    else:\r\n",
      "        return tree.getRootVal()\r\n",
      "\r\n",
      "def fill_values(formula):\r\n",
      "    \"\"\"returns genexp with the all fillings with 0 and 1\"\"\"\r\n",
      "    letters = ''.join(set(re.findall('[A-Z]', formula)))\r\n",
      "    for digits in product('10', repeat=len(letters)):\r\n",
      "         table = str.maketrans(letters, ''.join(digits))\r\n",
      "         yield formula.translate(table)\r\n",
      "        \r\n",
      "def is_tautology(formula):\r\n",
      "    for x in fill_values(formula):\r\n",
      "        if not evaluate_parse_tree(build_parse_tree(x)):\r\n",
      "            return False\r\n",
      "    return True\r\n"
     ]
    }
   ],
   "source": [
    "%cat porpositional_logic_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "~\n",
      "||\n",
      "False\n",
      "~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = \"~(~1 || 0)\"\n",
    "tr = build_parse_tree(F)\n",
    "inorder_traversal(tr)\n",
    "evaluate_parse_tree(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_tree_evaluate(tree):\n",
    "    opers = {'||': OR, '&&': AND, '~': NOT: implication, '==': equality, 'XR': xor} \n",
    "    leftT = tree.getLeftChild()\n",
    "    rightT = tree.getRightChild()\n",
    "    if leftT and not rightT:\n",
    "        fn = opers[tree.getRootVal()]\n",
    "        return fn(evaluate_parse_tree(leftT))\n",
    "    elif leftT and rightT:\n",
    "        fn = opers[tree.getRootVal()]\n",
    "        return fn(evaluate_parse_tree(leftT), evaluate_parse_tree(rightT))\n",
    "    else:\n",
    "        return tree.getRootVal()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
